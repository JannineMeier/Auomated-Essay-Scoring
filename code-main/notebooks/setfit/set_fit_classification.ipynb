{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552ec552",
   "metadata": {},
   "source": [
    "# SetFit for Multilabel Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7f258-5aaf-47c2-b81e-2f10fc349812",
   "metadata": {},
   "source": [
    "In this notebook, we'll learn how to do few-shot text classification on a multilabel dataset with SetFit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5604f73-f395-42cb-8082-9974a87ef9e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4d3b4-93cd-4774-8055-35a00b11f483",
   "metadata": {},
   "source": [
    "To be able to share your model with the community, there are a few more steps to follow.\n",
    "\n",
    "First, you have to store your authentication token from the Hugging Face Hub (sign up [here](https://huggingface.co/join) if you haven't already!). To do so, execute the following cell and input an [access token](https://huggingface.co/docs/hub/security-tokens) associated with your account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526a3b86-db3c-4c27-bb6c-eb39d73326f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/leonkrug/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleo1212\u001b[0m (\u001b[33mhslu_nlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/leonkrug/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset before preprocessing:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'score', 'unique_mistakes', 'repeated_mistakes_count', 'max_repeated_mistake', 'word_count', 'flesch_reading_ease', 'flesch_kincaid_grade', 'sentence_count', 'average_sentence_length', 'pos_noun_count', 'pos_verb_count', 'pos_adj_count', 'pos_adv_count', 'grammar_error_count', 'syntactic_complexity', 'spelling_mistake_count', 'error_density', 'tfidf_keywords_vector', 'lda_topic_vector', 'keyword_coverage', 'pronoun_usage', 'unique_word_proportion', 'long_word_proportion', 'imagery_word_proportion', 'positive_sentiment_score', 'negative_sentiment_score', 'visual_word_proportion', 'unique_visual_word_proportion', 'average_imagery_score', 'discourse_marker_count', 'neural_coherence_score', 'longformer_sentence_embedding', 'longformer_coherence_score', 'type_token_ratio', 'lexical_diversity', 'vocabulary_maturity', 'in_persuade_corpus'],\n",
      "        num_rows: 13845\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'score', 'unique_mistakes', 'repeated_mistakes_count', 'max_repeated_mistake', 'word_count', 'flesch_reading_ease', 'flesch_kincaid_grade', 'sentence_count', 'average_sentence_length', 'pos_noun_count', 'pos_verb_count', 'pos_adj_count', 'pos_adv_count', 'grammar_error_count', 'syntactic_complexity', 'spelling_mistake_count', 'error_density', 'tfidf_keywords_vector', 'lda_topic_vector', 'keyword_coverage', 'pronoun_usage', 'unique_word_proportion', 'long_word_proportion', 'imagery_word_proportion', 'positive_sentiment_score', 'negative_sentiment_score', 'visual_word_proportion', 'unique_visual_word_proportion', 'average_imagery_score', 'discourse_marker_count', 'neural_coherence_score', 'longformer_sentence_embedding', 'longformer_coherence_score', 'type_token_ratio', 'lexical_diversity', 'vocabulary_maturity', 'in_persuade_corpus'],\n",
      "        num_rows: 3462\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'score', 'unique_mistakes', 'repeated_mistakes_count', 'max_repeated_mistake', 'word_count', 'flesch_reading_ease', 'flesch_kincaid_grade', 'sentence_count', 'average_sentence_length', 'pos_noun_count', 'pos_verb_count', 'pos_adj_count', 'pos_adv_count', 'grammar_error_count', 'syntactic_complexity', 'spelling_mistake_count', 'error_density', 'tfidf_keywords_vector', 'lda_topic_vector', 'keyword_coverage', 'pronoun_usage', 'unique_word_proportion', 'long_word_proportion', 'imagery_word_proportion', 'positive_sentiment_score', 'negative_sentiment_score', 'visual_word_proportion', 'unique_visual_word_proportion', 'average_imagery_score', 'discourse_marker_count', 'neural_coherence_score', 'longformer_sentence_embedding', 'longformer_coherence_score', 'type_token_ratio', 'lexical_diversity', 'vocabulary_maturity', 'in_persuade_corpus'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import EarlyStoppingCallback\n",
    "import wandb\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from collections import Counter\n",
    "import kagglehub\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Clear memory for all GPUs before model assignment\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "\n",
    "# Load dataset from Hugging Face hub\n",
    "huggingface_username = 'HSLU-AICOMP-LearningAgencyLab'\n",
    "dataset_name = 'learning-agency-lab-automated-essay-scoring-2_V3'\n",
    "# dataset_name = 'learning-agency-lab-automated-essay-scoring-2'\n",
    "our_model_name = 'automated-essay-scoring-setfit'\n",
    "\n",
    "wandb_project = 'HSLU-AICOMP-LearningAgencyLab'\n",
    "wandb_entity = 'Leo1212'\n",
    "\n",
    "max_words=4096\n",
    "\n",
    "huggingface_hub.login(token=os.getenv('HUGGINGFACE_TOKEN'))\n",
    "wandb.login(key=os.getenv('WANDB_API_TOKEN'))\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(f\"{huggingface_username}/{dataset_name}\")\n",
    "\n",
    "# Inspect dataset before preprocessing\n",
    "print(\"\\nDataset before preprocessing:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8afffd",
   "metadata": {},
   "source": [
    "Only use the Kaggle Dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d18e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DatasetDict, concatenate_datasets\n",
    "\n",
    "# # Step 1: Filter out examples where in_persuade_corpus == False\n",
    "# filtered_dataset = dataset.filter(lambda example: example['in_persuade_corpus'] == False)\n",
    "\n",
    "# # Step 2: Count examples per score in the filtered dataset\n",
    "# score_counts = Counter(filtered_dataset['train']['score'])\n",
    "\n",
    "# # Step 3: Supplement data where needed\n",
    "# for score, count in score_counts.items():\n",
    "#     if count < 130:\n",
    "#         # Get additional examples where in_persuade_corpus == True for this score\n",
    "#         additional_examples = dataset['train'].filter(\n",
    "#             lambda example: example['in_persuade_corpus'] == True and example['score'] == score\n",
    "#         )\n",
    "\n",
    "#         # Determine how many examples we need to add\n",
    "#         num_to_add = min(130 - count, len(additional_examples))\n",
    "\n",
    "#         # Select only the required number of additional examples\n",
    "#         additional_examples = additional_examples.select(range(num_to_add))\n",
    "\n",
    "#         # Concatenate the additional examples to the filtered dataset\n",
    "#         filtered_dataset['train'] = concatenate_datasets([filtered_dataset['train'], additional_examples])\n",
    "\n",
    "\n",
    "# # Step 5: Create a new DatasetDict with the splits\n",
    "# dataset = DatasetDict({\n",
    "#     'train': filtered_dataset['train'],\n",
    "#     'eval': dataset['eval'],\n",
    "#     'test': dataset['test']\n",
    "# })\n",
    "\n",
    "# print(dataset)\n",
    "\n",
    "# # Print the first example in the training set\n",
    "# print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747b837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 4985, 2: 3775, 4: 3156, 1: 1012, 5: 787, 6: 130})\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already loaded the dataset with 'load_dataset'\n",
    "score_counts = Counter(dataset['train']['score'])\n",
    "print(score_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac48d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return len(words)\n",
    "\n",
    "def truncate_text(text, max_words=384):\n",
    "    words = text.split()\n",
    "    return ' '.join(words[:max_words])\n",
    "\n",
    "def subsample_dataset(dataset, split='train', score_column='score', num_per_score=15, max_words=384):\n",
    "    reduced_dataset_list = []\n",
    "\n",
    "    for score in range(1, 7):\n",
    "        filtered = dataset[split].filter(lambda x: x[score_column] == score)\n",
    "        filtered = filtered.map(lambda x: {'text': truncate_text(x['full_text'], max_words) if count_words(x['full_text']) > max_words else x['full_text']})\n",
    "\n",
    "        if len(filtered) > 0:\n",
    "            sample_count = min(len(filtered), num_per_score)\n",
    "            reduced_dataset_list.append(filtered.shuffle(seed=42).select(range(sample_count)))\n",
    "\n",
    "    reduced_dataset = Dataset.from_dict({k: sum([d[k] for d in reduced_dataset_list], []) for k in reduced_dataset_list[0].column_names})\n",
    "    return reduced_dataset\n",
    "\n",
    "def preprocess_datasets(num_per_score, max_words, fullEvalSet=False):\n",
    "\n",
    "    eval_num_per_score = num_per_score\n",
    "    if fullEvalSet == True:\n",
    "        eval_num_per_score = 10000\n",
    "\n",
    "    reduced_dataset_train = subsample_dataset(dataset, split='train', num_per_score=num_per_score, max_words=max_words)\n",
    "    reduced_dataset_eval = subsample_dataset(dataset, split='eval', num_per_score=eval_num_per_score, max_words=max_words)\n",
    "\n",
    "    def convert_label(record):\n",
    "        record['label'] = int(record['score'])\n",
    "        return record\n",
    "\n",
    "    train_dataset = reduced_dataset_train.map(convert_label)\n",
    "    eval_dataset = reduced_dataset_eval.map(convert_label)\n",
    "\n",
    "    columns_to_keep = ['text', 'label']\n",
    "    train_dataset = train_dataset.remove_columns([col for col in train_dataset.column_names if col not in columns_to_keep])\n",
    "    eval_dataset = eval_dataset.remove_columns([col for col in eval_dataset.column_names if col not in columns_to_keep])\n",
    "\n",
    "    train_dataset = train_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "    eval_dataset = eval_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7985f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model classification head: LogisticRegression()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ad7caa459e4d398e88a31763c75b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95926f3d90fd4d1a88671a7d6214c516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eab2799e1a3418f9508ce259abd8df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d62cbbdf8fc4327ae3aea277dc60d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c24524f9644b6e95be98fa2e414a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55794c8a90344b8f978dd6681c3701df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e19e060d864ed584874fb696ea58db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddd48bf78ac4ded914599c2a12963cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc28c2de7e64f52a62d7615823d1bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270af55ab36d45d79c3d18e59dad1acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/787 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27188bff74e1471b8f1d0f532aa3f80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf9012ffa1548de90fb99a059aa0e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47c37f3cb224ae5a77996f84e194dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0398d2ee0c094ef0815681accb8d423f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafcdd461f8b467b8ae20d19700083dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313c9f719e3e427e83ecf8a6490b741a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e9eb83d45f493a939e106811a119c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_id = \"allenai/longformer-base-4096\"\n",
    "base_model_id = 'Leo1212/longformer-base-4096-sentence-transformers-all-nli-stsb-quora-nq'\n",
    "model = SetFitModel.from_pretrained(base_model_id) # revision=\"2104f5d5c622eff94ccb500ec8f722910e9c8f97\"\n",
    "\n",
    "# Set the device to GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model classification head: {model.model_head}\")\n",
    "\n",
    "def compute_qwk(y_pred, y_true):\n",
    "    y_pred = np.argmax(y_pred, axis=1) if y_pred.ndim > 1 else y_pred\n",
    "    return {\"qwk\": cohen_kappa_score(y_true, y_pred, weights='quadratic')}\n",
    "\n",
    "num_iterations=10\n",
    "num_epochs=10\n",
    "batch_size=2\n",
    "num_per_score=130\n",
    "use_amp=True\n",
    "loss=CosineSimilarityLoss\n",
    "\n",
    "train_dataset, eval_dataset = preprocess_datasets(num_per_score, max_words, fullEvalSet=False)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    report_to=\"wandb\",\n",
    "    use_amp=use_amp,\n",
    "    logging_strategy=\"epoch\",       \n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    batch_size=batch_size,\n",
    "    num_iterations=num_iterations,\n",
    "    num_epochs=num_epochs,\n",
    "    loss=loss,  \n",
    "    load_best_model_at_end = True,\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,  \n",
    "    eval_dataset=eval_dataset,\n",
    "    metric=compute_qwk,\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"},  \n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3e642",
   "metadata": {},
   "source": [
    "The main arguments to notice in the trainer is the following:\n",
    "\n",
    "* `loss_class`: The loss function to use for contrastive learning with the Sentence Transformer body\n",
    "* `num_iterations`: The number of text pairs to generate for contrastive learning\n",
    "* `column_mapping`: The `SetFitTrainer` expects the inputs to be found in a `text` and `label` column. This mapping automatically formats the training and evaluation datasets for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3c5ae-c287-4936-b1ac-5eca10c7f39c",
   "metadata": {},
   "source": [
    "Now that we've created a trainer, we can train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b5a468b-2796-47c3-8907-c0147ee58dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 15600\n",
      "  Batch size = 2\n",
      "  Num epochs = 10\n",
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241201_011450-u40d7l0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/HSLU-AICOMP-LearningAgencyLab/runs/u40d7l0b' target=\"_blank\">glorious-cloud-4035</a></strong> to <a href='https://wandb.ai/hslu_nlp/HSLU-AICOMP-LearningAgencyLab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/HSLU-AICOMP-LearningAgencyLab' target=\"_blank\">https://wandb.ai/hslu_nlp/HSLU-AICOMP-LearningAgencyLab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/HSLU-AICOMP-LearningAgencyLab/runs/u40d7l0b' target=\"_blank\">https://wandb.ai/hslu_nlp/HSLU-AICOMP-LearningAgencyLab/runs/u40d7l0b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c871d09269454f6684b2f8a36dd64c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2925, 'grad_norm': 4.681674003601074, 'learning_rate': 5.128205128205129e-09, 'epoch': 0.0}\n",
      "{'embedding_loss': 0.1808, 'grad_norm': 9.130257606506348, 'learning_rate': 2e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f872b22c2744ab802e08200923ecd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.19862136244773865, 'eval_embedding_runtime': 1229.2116, 'eval_embedding_samples_per_second': 10.999, 'eval_embedding_steps_per_second': 2.75, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a25a9de1e2d4c2d98454cf3e8913b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0597, 'grad_norm': 0.4967077374458313, 'learning_rate': 1.7777777777777777e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db873d5f123a4be3b68bd5fa3fcd91b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.25149649381637573, 'eval_embedding_runtime': 1230.051, 'eval_embedding_samples_per_second': 10.991, 'eval_embedding_steps_per_second': 2.748, 'epoch': 2.0}\n",
      "{'embedding_loss': 0.0181, 'grad_norm': 0.01842939667403698, 'learning_rate': 1.555555555555556e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea913e5f1b24c8e97fcf590c64419e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.3038812577724457, 'eval_embedding_runtime': 1230.1214, 'eval_embedding_samples_per_second': 10.991, 'eval_embedding_steps_per_second': 2.748, 'epoch': 3.0}\n",
      "{'embedding_loss': 0.0222, 'grad_norm': 0.005139842163771391, 'learning_rate': 1.3333333333333333e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775493132eb043d0bb9f4fc60f1cacae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.30127018690109253, 'eval_embedding_runtime': 1229.2187, 'eval_embedding_samples_per_second': 10.999, 'eval_embedding_steps_per_second': 2.75, 'epoch': 4.0}\n",
      "{'embedding_loss': 0.0082, 'grad_norm': 0.18250790238380432, 'learning_rate': 1.1111111111111113e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aef38f04164d7eba4b19b561ecb409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.2740993797779083, 'eval_embedding_runtime': 1230.1654, 'eval_embedding_samples_per_second': 10.99, 'eval_embedding_steps_per_second': 2.748, 'epoch': 5.0}\n",
      "{'train_runtime': 19446.6142, 'train_samples_per_second': 8.022, 'train_steps_per_second': 2.005, 'train_loss': 0.05778299667285039, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "wandb.config.update({\n",
    "    \"num_iterations\": num_iterations,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"device\": device.type,\n",
    "    \"loss_class\": str(loss),\n",
    "    \"base_model_id\": base_model_id,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_per_score\": num_per_score,\n",
    "    \"max_words\": max_words,\n",
    "    \"use_amp\": use_amp,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799f994",
   "metadata": {},
   "source": [
    "The final step is to compute the model's performance using the `evaluate()` method. The default metric measures 'subset accuracy', which measures the fraction of samples where we predict all 8 labels correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453c11d0-a1e4-49c2-859a-cc70e033b4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc539f8357f24394bffdc1eb844f9160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe10f568bfc44885ab4a55048270ca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdbd380061248c784c9c231f40b05b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e883f01df0b742b1ae58cdf0f9aed35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the evaluation dataset\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'qwk': 0.7462769974528534}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, full_eval_dataset = preprocess_datasets(num_per_score, max_words, fullEvalSet=True)\n",
    "\n",
    "metrics = trainer.evaluate(full_eval_dataset)\n",
    "qwk_score = metrics.get(\"qwk\", -1)\n",
    "wandb.log({\"eval_qwk\": qwk_score})\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021b168-02d2-4cc8-942d-65d3b821e253",
   "metadata": {},
   "source": [
    "And once the model is trained, you can push it to the Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c420c4b9-1552-45a5-888c-cdbb78f8e4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc0b3fe4fea4dbda442d60061699673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/595M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3023e8b36c4586b98c9ebe84e59f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_head.pkl:   0%|          | 0.00/37.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dc665301a043a38f861b2824256479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit/commit/19c9509ded90e4098505369211f4a491eff49017', commit_message='Add SetFit model', commit_description='', oid='19c9509ded90e4098505369211f4a491eff49017', pr_url=None, repo_url=RepoUrl('https://huggingface.co/HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit', endpoint='https://huggingface.co', repo_type='model', repo_id='HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(f\"{huggingface_username}/{our_model_name}\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2c738",
   "metadata": {},
   "source": [
    "Upload to KaggleHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5e5623-0452-4d36-8eb0-cfb36c8664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(f\"{huggingface_username}/{our_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef05ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Model https://www.kaggle.com/models/leo1212abc/automated-essay-scoring-setfit/transformers/default ...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/config_setfit.json\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 53.0/53.0 [00:00<00:00, 126B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/config_setfit.json (53B)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1.41k/1.41k [00:00<00:00, 4.08kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/tokenizer_config.json (1KB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 3.56M/3.56M [00:01<00:00, 2.89MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/tokenizer.json (3MB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 798k/798k [00:00<00:00, 811kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/vocab.json (780KB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 4.25k/4.25k [00:00<00:00, 11.1kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/README.md (4KB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/config_sentence_transformers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 201/201 [00:00<00:00, 574B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/config_sentence_transformers.json (201B)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 913/913 [00:00<00:00, 2.65kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/config.json (913B)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/modules.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 229/229 [00:00<00:00, 683B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/modules.json (229B)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 958/958 [00:00<00:00, 2.70kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/special_tokens_map.json (958B)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/merges.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 456k/456k [00:00<00:00, 511kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/merges.txt (446KB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 595M/595M [00:14<00:00, 40.7MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/model.safetensors (567MB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/sentence_bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 54.0/54.0 [00:00<00:00, 157B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/sentence_bert_config.json (54B)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/model_head.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 37.8k/37.8k [00:00<00:00, 89.6kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/model_head.pkl (37KB)\n",
      "Starting upload for file ../src/models/automated-essay-scoring-setfit/1_Pooling/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 296/296 [00:00<00:00, 859B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: ../src/models/automated-essay-scoring-setfit/1_Pooling/config.json (296B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Your model instance version has been created.\n",
      "Files are being processed...\n",
      "See at: https://www.kaggle.com/models/leo1212abc/automated-essay-scoring-setfit/transformers/default\n"
     ]
    }
   ],
   "source": [
    "VARIATION_SLUG = 'default'\n",
    "\n",
    "LOCAL_MODEL_DIR = f\"../src/models/{our_model_name}\"\n",
    "model.save_pretrained(LOCAL_MODEL_DIR)\n",
    "\n",
    "# Compress the model directory (optional but helpful for large files)\n",
    "shutil.make_archive(our_model_name, 'zip', LOCAL_MODEL_DIR)\n",
    "\n",
    "kagglehub.model_upload(\n",
    "  handle = f\"leo1212abc/{our_model_name}/transformers/{VARIATION_SLUG}\",\n",
    "  local_model_dir = LOCAL_MODEL_DIR,\n",
    "  version_notes = f\"Metrics: {str(metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02173d18-4874-4148-8789-90ac695717bc",
   "metadata": {},
   "source": [
    "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `your-username/the-name-you-picked` so for instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0e4e5-6645-4306-a9ab-06d0db9e23d0",
   "metadata": {},
   "source": [
    "Run inference. As is usual in toxicity models, it tends to think any mention of topics such as race or gender are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e51180c-5a62-4dfa-a543-334982db2d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(\n",
    "    [\n",
    "        dataset['test'][0]['full_text'],\n",
    "        dataset['test'][1]['full_text'],\n",
    "        dataset['test'][2]['full_text'],\n",
    "    ]\n",
    ")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465afcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f813a1ed520048309c725e3cc9be9b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbc5482c0684e8b97b95ac1e7056d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d82e45d6047490a8b20e0914b7274ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f003b873be0c401784a85c09f6f4b069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173d4aab5dff41eca3532c06cd6c2aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cc9016cf45488aa18dbde8d15780e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305f824d49fb4a918044b10093eeeccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ea27fe2fc14cc3bed12ec72fc059c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a097d1e056724bd5a8245af13220dd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c217f2648b34e84b5edcdd36d74a2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85639b654e24769be25c4d3005c3c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1176882973c74f4785f8792cfde65700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4900f9b44a514f889b00682848a65606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file model.safetensors:   0%|          | 8.00k/567M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1b2fb550514febb56b1dcb526e066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file model_head.pkl:  20%|##        | 7.46k/36.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0948ff088b4318a6807d9cccd56849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file model_head.pkl:   3%|2         | 1.00k/36.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936acf238dc744c79e43285dfb42c4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file model.safetensors:   0%|          | 1.00k/567M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit\n",
      "   19c9509..ffbc35c  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit/commit/ffbc35cbfcc45f4a5855f013fd1d7b268c42a436'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, Repository\n",
    "\n",
    "def cleanup_yaml_text(text):\n",
    "    \"\"\"\n",
    "    Cleans up a text input to make it YAML-valid by escaping necessary characters\n",
    "    and formatting it properly for multi-line strings.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and formatted text suitable for YAML.\n",
    "    \"\"\"\n",
    "    # Escape single quotes for YAML compliance\n",
    "    text = text.replace(\"'\", \"''\")\n",
    "    \n",
    "    # Format text as a multi-line YAML string with '|-' to preserve formatting\n",
    "    formatted_text = \"|-\\n  \" + text.replace(\"\\n\", \"\\n  \")\n",
    "    return formatted_text\n",
    "\n",
    "# Generate cleaned text for each label\n",
    "widget_texts = [\n",
    "    cleanup_yaml_text(train_dataset.filter(lambda x: x['label'] == i)['text'][0])\n",
    "    for i in range(1, 7)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "best_qwk_score=qwk_score\n",
    "best_hyperparameters = wandb.config\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Convert the dictionary to a SimpleNamespace object\n",
    "best_hyperparameters = SimpleNamespace(**best_hyperparameters)\n",
    "\n",
    "examples = []\n",
    "examples.append(train_dataset.filter(lambda x: x['label'] == 1)['text'][0].replace('\\n', ''))\n",
    "examples.append(train_dataset.filter(lambda x: x['label'] == 2)['text'][0].replace('\\n', ''))\n",
    "examples.append(train_dataset.filter(lambda x: x['label'] == 3)['text'][0].replace('\\n', ''))\n",
    "examples.append(train_dataset.filter(lambda x: x['label'] == 4)['text'][0].replace('\\n', ''))\n",
    "examples.append(train_dataset.filter(lambda x: x['label'] == 5)['text'][0].replace('\\n', ''))\n",
    "examples.append(train_dataset.filter(lambda x: x['label'] == 6)['text'][0].replace('\\n', ''))\n",
    "\n",
    "# Define your variables\n",
    "model_name = f\"{huggingface_username}/{our_model_name}\"\n",
    "\n",
    "# Check if the directory already exists, if so, delte to allow for updates. git fetch/pull does not work\n",
    "if os.path.exists(model_name):\n",
    "    shutil.rmtree(model_name)\n",
    "\n",
    "repo = Repository(local_dir=model_name, clone_from=model_name)\n",
    "\n",
    "# Create or update the model card with desired information\n",
    "# model_card = ModelCard.load(f\"{model_name}/README.md\")\n",
    "\n",
    "# Add QWK score and hyperparameters to the model card's content\n",
    "model_card_content = f\"\"\"\n",
    "---\n",
    "base_model: {base_model_id}\n",
    "library_name: setfit\n",
    "metrics:\n",
    "- accuracy\n",
    "pipeline_tag: text-classification\n",
    "tags:\n",
    "- setfit\n",
    "- sentence-transformers\n",
    "- text-classification\n",
    "- generated_from_setfit_trainer\n",
    "inference: true\n",
    "model-index:\n",
    "- name: SetFit with {base_model_id}\n",
    "  results:\n",
    "  - task:\n",
    "      type: text-classification\n",
    "      name: Text Classification\n",
    "    dataset:\n",
    "      name: Unknown\n",
    "      type: unknown\n",
    "      split: test\n",
    "    metrics:\n",
    "    - type: qwk\n",
    "      value: {best_qwk_score}\n",
    "      name: QWK\n",
    "---\n",
    "\n",
    "# SetFit with {base_model_id}\n",
    "\n",
    "This is a [SetFit](https://github.com/huggingface/setfit) model that can be used for Text Classification. This SetFit model uses [{base_model_id}](https://huggingface.co/{base_model_id}) as the Sentence Transformer embedding model. A [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) instance is used for classification.\n",
    "\n",
    "The model has been trained using an efficient few-shot learning technique that involves:\n",
    "\n",
    "1. Fine-tuning a [Sentence Transformer](https://www.sbert.net) with contrastive learning.\n",
    "2. Training a classification head with features from the fine-tuned Sentence Transformer.\n",
    "\n",
    "## Model Details\n",
    "\n",
    "### Model Description\n",
    "- **Model Type:** SetFit\n",
    "- **Sentence Transformer body:** [{base_model_id}](https://huggingface.co/{base_model_id})\n",
    "- **Classification head:** a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) instance\n",
    "- **Maximum Sequence Length:** 4098 tokens\n",
    "- **Number of Classes:** 6 classes\n",
    "<!-- - **Training Dataset:** [Unknown](https://huggingface.co/datasets/unknown) -->\n",
    "<!-- - **Language:** Unknown -->\n",
    "<!-- - **License:** Unknown -->\n",
    "\n",
    "### Model Sources\n",
    "\n",
    "- **Repository:** [SetFit on GitHub](https://github.com/huggingface/setfit)\n",
    "- **Paper:** [Efficient Few-Shot Learning Without Prompts](https://arxiv.org/abs/2209.11055)\n",
    "- **Blogpost:** [SetFit: Efficient Few-Shot Learning Without Prompts](https://huggingface.co/blog/setfit)\n",
    "\n",
    "### Model Labels\n",
    "| Label | Examples                                                                                                                                                                                                                                                                                                                                           |\n",
    "|:------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 1     | <ul><li>'{examples[0]}'</li></ul>|\n",
    "| 2     | <ul><li>'{examples[1]}'</li></ul>|\n",
    "| 3     | <ul><li>'{examples[2]}'</li></ul>|\n",
    "| 4     | <ul><li>'{examples[3]}'</li></ul>|\n",
    "| 5     | <ul><li>'{examples[4]}'</li></ul>|\n",
    "| 6     | <ul><li>'{examples[5]}'</li></ul>|\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "### Metrics\n",
    "| Label   | QWK |\n",
    "|:--------|:---------|\n",
    "| **all** | {best_qwk_score}   |\n",
    "\n",
    "## Uses\n",
    "\n",
    "### Direct Use for Inference\n",
    "\n",
    "First install the SetFit library:\n",
    "\n",
    "```bash\n",
    "pip install setfit\n",
    "```\n",
    "\n",
    "Then you can load this model and run inference.\n",
    "\n",
    "```python\n",
    "from setfit import SetFitModel\n",
    "\n",
    "# Download from the 🤗 Hub\n",
    "model = SetFitModel.from_pretrained(\"HSLU-AICOMP-LearningAgencyLab/automated-essay-scoring-setfit\")\n",
    "# Run inference\n",
    "preds = model(\"In source 1, Elisabeth Rosenthal is inform us about the low car usage in Vauban,Germany. In Vauban, the residents no longer use cars. They use other means of transportation such as bicycles and walking etc. It is shown in paragraph 3 that 70 percent of Vauban's families do not own cars and that 57 percent sold a car to move there.\n",
    "\n",
    "In Europe, passager cars are responsible for 12 percent of greenhouse gas and up to 50 percent in some car intense areas in the United States, paragraph 5. Efforts in past 20 ears have been made to make cities denser and better for walking. Populated with 5,500 , Vauban may be the most advanced experiment in low car suburban life, paragraph 6.\n",
    "\n",
    "Scarsdale and Levittown, New York suburbs has strong apppeal, Many new suburbs may look more like Vauban. Cities around the world where emissions from cars are choking cities, their developing a little bit of the Vauban life style now, paragraph 8. The Environmental Protection Agency in the United States, is promoting the \\\"car reduced\\\" communities. Many experts expect public transport serving suburbs to play a much larger role in a six- year federal bill. 80 percent of apporpriation have by law gonre to highways and only 20 percent to other transport, paragraph 9.    \")\n",
    "```\n",
    "\n",
    "<!--\n",
    "### Downstream Use\n",
    "\n",
    "*List how someone could finetune this model on their own dataset.*\n",
    "-->\n",
    "\n",
    "<!--\n",
    "### Out-of-Scope Use\n",
    "\n",
    "*List how the model may foreseeably be misused and address what users ought not to do with the model.*\n",
    "-->\n",
    "\n",
    "<!--\n",
    "## Bias, Risks and Limitations\n",
    "\n",
    "*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*\n",
    "-->\n",
    "\n",
    "<!--\n",
    "### Recommendations\n",
    "\n",
    "*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*\n",
    "-->\n",
    "\n",
    "## Training Details\n",
    "\n",
    "### Training Hyperparameters\n",
    "- batch_size: {best_hyperparameters.batch_size}\n",
    "- num_epochs: {best_hyperparameters.num_epochs})\n",
    "- max_steps: {best_hyperparameters.max_steps}\n",
    "- sampling_strategy: {best_hyperparameters.sampling_strategy}\n",
    "- num_iterations: {best_hyperparameters.num_iterations}\n",
    "- num_per_score: {best_hyperparameters.num_per_score}\n",
    "- body_learning_rate: {best_hyperparameters.body_learning_rate}\n",
    "- head_learning_rate: {best_hyperparameters.head_learning_rate}\n",
    "- loss: {best_hyperparameters.loss}\n",
    "- distance_metric: {best_hyperparameters.distance_metric}\n",
    "- margin: {best_hyperparameters.margin}\n",
    "- end_to_end: {best_hyperparameters.end_to_end}\n",
    "- use_amp: {best_hyperparameters.use_amp}\n",
    "- warmup_proportion: {best_hyperparameters.warmup_proportion}\n",
    "- l2_weight: {best_hyperparameters.l2_weight}\n",
    "- seed: {best_hyperparameters.seed}\n",
    "- eval_max_steps: {best_hyperparameters.eval_max_steps}\n",
    "- load_best_model_at_end: {best_hyperparameters.load_best_model_at_end}\n",
    "- metric_for_best_model: qwk\n",
    "\n",
    "### Framework Versions\n",
    "- Python: 3.11.9\n",
    "- SetFit: 1.1.0\n",
    "- Sentence Transformers: 3.1.1\n",
    "- Transformers: 4.45.2\n",
    "- PyTorch: 2.3.1+cu121\n",
    "- Datasets: 3.0.1\n",
    "- Tokenizers: 0.20.0\n",
    "\n",
    "<!--\n",
    "## Glossary\n",
    "\n",
    "*Clearly define terms in order to be accessible across audiences.*\n",
    "-->\n",
    "\n",
    "<!--\n",
    "## Model Card Authors\n",
    "\n",
    "*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*\n",
    "-->\n",
    "\n",
    "<!--\n",
    "## Model Card Contact\n",
    "\n",
    "*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*\n",
    "-->\n",
    "\"\"\"\n",
    "\n",
    "# Write content to the model card\n",
    "with open(f\"{repo.local_dir}/README.md\", \"w\") as file:\n",
    "    file.write(model_card_content)\n",
    "\n",
    "# Push the changes to the hub\n",
    "repo.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78875461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
