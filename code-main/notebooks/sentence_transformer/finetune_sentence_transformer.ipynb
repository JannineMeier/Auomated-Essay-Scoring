{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by: https://huggingface.co/blog/train-sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleo1212\u001b[0m (\u001b[33mhslu_nlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/leonkrug/.netrc\n",
      "No sentence-transformers model found with name allenai/longformer-base-4096. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mbg5ckdp\n",
      "Sweep URL: https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8yu15rc5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00045788302667372136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241121_221752-8yu15rc5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/8yu15rc5' target=\"_blank\">dark-sweep-1</a></strong> to <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/8yu15rc5' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/8yu15rc5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705e1ed902a846449254b48b0ba9557e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n",
      "Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3109, 'grad_norm': 2.5075600147247314, 'learning_rate': 0.00045567705949085607, 'epoch': 0.05}\n",
      "{'loss': 3.5823, 'grad_norm': 0.04463895410299301, 'learning_rate': 0.0004534488098111942, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5637f618b3465c96edf93a6559a792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:192: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson_cosine, _ = pearsonr(labels, cosine_scores)\n",
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:193: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman_cosine, _ = spearmanr(labels, cosine_scores)\n",
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:192: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson_cosine, _ = pearsonr(labels, cosine_scores)\n",
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:193: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman_cosine, _ = spearmanr(labels, cosine_scores)\n",
      "early stopping required metric_for_best_model, but did not find eval_aggregate_score so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_all-nli-triplet_loss': 3.4648938179016113, 'eval_sts-dev_pearson_cosine': nan, 'eval_sts-dev_spearman_cosine': nan, 'eval_sts-dev_pearson_manhattan': 0.1953366031192939, 'eval_sts-dev_spearman_manhattan': 0.18628029922412706, 'eval_sts-dev_pearson_euclidean': 0.12038330059026879, 'eval_sts-dev_spearman_euclidean': 0.11701423250889276, 'eval_sts-dev_pearson_dot': -0.020898059060793592, 'eval_sts-dev_spearman_dot': -0.019267171663208498, 'eval_sts-dev_pearson_max': nan, 'eval_sts-dev_spearman_max': nan, 'eval_triplet-dev_cosine_accuracy': 0.5089611178614823, 'eval_triplet-dev_dot_accuracy': 0.24939246658566222, 'eval_triplet-dev_manhattan_accuracy': 0.511543134872418, 'eval_triplet-dev_euclidean_accuracy': 0.5103280680437424, 'eval_triplet-dev_max_accuracy': 0.511543134872418, 'eval_label-accuracy-dev_pearson_cosine': nan, 'eval_label-accuracy-dev_spearman_cosine': nan, 'eval_label-accuracy-dev_pearson_manhattan': 0.049476403113581605, 'eval_label-accuracy-dev_spearman_manhattan': 0.05279290870444774, 'eval_label-accuracy-dev_pearson_euclidean': 0.03906753540286213, 'eval_label-accuracy-dev_spearman_euclidean': 0.04333503769885663, 'eval_label-accuracy-dev_pearson_dot': -0.011658647110881755, 'eval_label-accuracy-dev_spearman_dot': -0.009275521591297707, 'eval_label-accuracy-dev_pearson_max': nan, 'eval_label-accuracy-dev_spearman_max': nan, 'eval_sequential_score': nan, 'eval_all-nli-triplet_runtime': 606.3367, 'eval_all-nli-triplet_samples_per_second': 10.859, 'eval_all-nli-triplet_steps_per_second': 0.679, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f006cfe7d8d842349c40a6cb5f24bed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_aggregate_score so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_loss': 4.755264759063721, 'eval_stsb_runtime': 42.8844, 'eval_stsb_samples_per_second': 34.978, 'eval_stsb_steps_per_second': 2.192, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ae20d9da554c34ac49bb000d7d2890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_aggregate_score so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_quora_loss': 2.7670435905456543, 'eval_quora_runtime': 28.1058, 'eval_quora_samples_per_second': 35.58, 'eval_quora_steps_per_second': 2.242, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d343c3dee04c62afe15ee29c68f975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_aggregate_score so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_natural-questions_loss': 2.767043113708496, 'eval_natural-questions_runtime': 28.6045, 'eval_natural-questions_samples_per_second': 34.96, 'eval_natural-questions_steps_per_second': 2.202, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a7cc97f9bc4e4a95b38897c310b2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/3 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3022, in _save_checkpoint\n",
      "    metric_value = metrics[metric_to_check]\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'eval_aggregate_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2467, in _inner_training_loop\n",
      "    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2918, in _maybe_log_save_evaluate\n",
      "    self._save_checkpoint(model, trial, metrics=metrics)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3024, in _save_checkpoint\n",
      "    raise KeyError(\n",
      "KeyError: \"The `metric_for_best_model` training argument is set to 'eval_aggregate_score', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_all-nli-triplet_loss', 'eval_sts-dev_pearson_cosine', 'eval_sts-dev_spearman_cosine', 'eval_sts-dev_pearson_manhattan', 'eval_sts-dev_spearman_manhattan', 'eval_sts-dev_pearson_euclidean', 'eval_sts-dev_spearman_euclidean', 'eval_sts-dev_pearson_dot', 'eval_sts-dev_spearman_dot', 'eval_sts-dev_pearson_max', 'eval_sts-dev_spearman_max', 'eval_triplet-dev_cosine_accuracy', 'eval_triplet-dev_dot_accuracy', 'eval_triplet-dev_manhattan_accuracy', 'eval_triplet-dev_euclidean_accuracy', 'eval_triplet-dev_max_accuracy', 'eval_label-accuracy-dev_pearson_cosine', 'eval_label-accuracy-dev_spearman_cosine', 'eval_label-accuracy-dev_pearson_manhattan', 'eval_label-accuracy-dev_spearman_manhattan', 'eval_label-accuracy-dev_pearson_euclidean', 'eval_label-accuracy-dev_spearman_euclidean', 'eval_label-accuracy-dev_pearson_dot', 'eval_label-accuracy-dev_spearman_dot', 'eval_label-accuracy-dev_pearson_max', 'eval_label-accuracy-dev_spearman_max', 'eval_sequential_score', 'eval_all-nli-triplet_runtime', 'eval_all-nli-triplet_samples_per_second', 'eval_all-nli-triplet_steps_per_second', 'epoch', 'aggregate_score', 'eval_stsb_loss', 'eval_stsb_runtime', 'eval_stsb_samples_per_second', 'eval_stsb_steps_per_second', 'eval_quora_loss', 'eval_quora_runtime', 'eval_quora_samples_per_second', 'eval_quora_steps_per_second', 'eval_natural-questions_loss', 'eval_natural-questions_runtime', 'eval_natural-questions_samples_per_second', 'eval_natural-questions_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdcd554be7e4d1c855c93c9aa1950fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.036 MB of 0.036 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>aggregate_score</td><td> ▁▁▁ </td></tr><tr><td>eval/all-nli-triplet_loss</td><td>▁</td></tr><tr><td>eval/all-nli-triplet_runtime</td><td>▁</td></tr><tr><td>eval/all-nli-triplet_samples_per_second</td><td>▁</td></tr><tr><td>eval/all-nli-triplet_steps_per_second</td><td>▁</td></tr><tr><td>eval/label-accuracy-dev_pearson_dot</td><td>▁</td></tr><tr><td>eval/label-accuracy-dev_pearson_euclidean</td><td>▁</td></tr><tr><td>eval/label-accuracy-dev_pearson_manhattan</td><td>▁</td></tr><tr><td>eval/label-accuracy-dev_spearman_dot</td><td>▁</td></tr><tr><td>eval/label-accuracy-dev_spearman_euclidean</td><td>▁</td></tr><tr><td>eval/label-accuracy-dev_spearman_manhattan</td><td>▁</td></tr><tr><td>eval/natural-questions_loss</td><td>▁</td></tr><tr><td>eval/natural-questions_runtime</td><td>▁</td></tr><tr><td>eval/natural-questions_samples_per_second</td><td>▁</td></tr><tr><td>eval/natural-questions_steps_per_second</td><td>▁</td></tr><tr><td>eval/quora_loss</td><td>▁</td></tr><tr><td>eval/quora_runtime</td><td>▁</td></tr><tr><td>eval/quora_samples_per_second</td><td>▁</td></tr><tr><td>eval/quora_steps_per_second</td><td>▁</td></tr><tr><td>eval/sts-dev_pearson_dot</td><td>▁</td></tr><tr><td>eval/sts-dev_pearson_euclidean</td><td>▁</td></tr><tr><td>eval/sts-dev_pearson_manhattan</td><td>▁</td></tr><tr><td>eval/sts-dev_spearman_dot</td><td>▁</td></tr><tr><td>eval/sts-dev_spearman_euclidean</td><td>▁</td></tr><tr><td>eval/sts-dev_spearman_manhattan</td><td>▁</td></tr><tr><td>eval/stsb_loss</td><td>▁</td></tr><tr><td>eval/stsb_runtime</td><td>▁</td></tr><tr><td>eval/stsb_samples_per_second</td><td>▁</td></tr><tr><td>eval/stsb_steps_per_second</td><td>▁</td></tr><tr><td>eval/triplet-dev_cosine_accuracy</td><td>▁</td></tr><tr><td>eval/triplet-dev_dot_accuracy</td><td>▁</td></tr><tr><td>eval/triplet-dev_euclidean_accuracy</td><td>▁</td></tr><tr><td>eval/triplet-dev_manhattan_accuracy</td><td>▁</td></tr><tr><td>eval/triplet-dev_max_accuracy</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆████</td></tr><tr><td>train/global_step</td><td>▁▆█████████</td></tr><tr><td>train/grad_norm</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>aggregate_score</td><td>nan</td></tr><tr><td>eval/all-nli-triplet_loss</td><td>3.46489</td></tr><tr><td>eval/all-nli-triplet_runtime</td><td>606.3367</td></tr><tr><td>eval/all-nli-triplet_samples_per_second</td><td>10.859</td></tr><tr><td>eval/all-nli-triplet_steps_per_second</td><td>0.679</td></tr><tr><td>eval/label-accuracy-dev_pearson_cosine</td><td>nan</td></tr><tr><td>eval/label-accuracy-dev_pearson_dot</td><td>-0.01166</td></tr><tr><td>eval/label-accuracy-dev_pearson_euclidean</td><td>0.03907</td></tr><tr><td>eval/label-accuracy-dev_pearson_manhattan</td><td>0.04948</td></tr><tr><td>eval/label-accuracy-dev_pearson_max</td><td>nan</td></tr><tr><td>eval/label-accuracy-dev_spearman_cosine</td><td>nan</td></tr><tr><td>eval/label-accuracy-dev_spearman_dot</td><td>-0.00928</td></tr><tr><td>eval/label-accuracy-dev_spearman_euclidean</td><td>0.04334</td></tr><tr><td>eval/label-accuracy-dev_spearman_manhattan</td><td>0.05279</td></tr><tr><td>eval/label-accuracy-dev_spearman_max</td><td>nan</td></tr><tr><td>eval/natural-questions_loss</td><td>2.76704</td></tr><tr><td>eval/natural-questions_runtime</td><td>28.6045</td></tr><tr><td>eval/natural-questions_samples_per_second</td><td>34.96</td></tr><tr><td>eval/natural-questions_steps_per_second</td><td>2.202</td></tr><tr><td>eval/quora_loss</td><td>2.76704</td></tr><tr><td>eval/quora_runtime</td><td>28.1058</td></tr><tr><td>eval/quora_samples_per_second</td><td>35.58</td></tr><tr><td>eval/quora_steps_per_second</td><td>2.242</td></tr><tr><td>eval/sequential_score</td><td>nan</td></tr><tr><td>eval/sts-dev_pearson_cosine</td><td>nan</td></tr><tr><td>eval/sts-dev_pearson_dot</td><td>-0.0209</td></tr><tr><td>eval/sts-dev_pearson_euclidean</td><td>0.12038</td></tr><tr><td>eval/sts-dev_pearson_manhattan</td><td>0.19534</td></tr><tr><td>eval/sts-dev_pearson_max</td><td>nan</td></tr><tr><td>eval/sts-dev_spearman_cosine</td><td>nan</td></tr><tr><td>eval/sts-dev_spearman_dot</td><td>-0.01927</td></tr><tr><td>eval/sts-dev_spearman_euclidean</td><td>0.11701</td></tr><tr><td>eval/sts-dev_spearman_manhattan</td><td>0.18628</td></tr><tr><td>eval/sts-dev_spearman_max</td><td>nan</td></tr><tr><td>eval/stsb_loss</td><td>4.75526</td></tr><tr><td>eval/stsb_runtime</td><td>42.8844</td></tr><tr><td>eval/stsb_samples_per_second</td><td>34.978</td></tr><tr><td>eval/stsb_steps_per_second</td><td>2.192</td></tr><tr><td>eval/triplet-dev_cosine_accuracy</td><td>0.50896</td></tr><tr><td>eval/triplet-dev_dot_accuracy</td><td>0.24939</td></tr><tr><td>eval/triplet-dev_euclidean_accuracy</td><td>0.51033</td></tr><tr><td>eval/triplet-dev_manhattan_accuracy</td><td>0.51154</td></tr><tr><td>eval/triplet-dev_max_accuracy</td><td>0.51154</td></tr><tr><td>train/epoch</td><td>0.12165</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/grad_norm</td><td>0.04464</td></tr><tr><td>train/learning_rate</td><td>0.00045</td></tr><tr><td>train/loss</td><td>3.5823</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-1</strong> at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/8yu15rc5' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/8yu15rc5</a><br/> View project at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_221752-8yu15rc5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 8yu15rc5 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3022, in _save_checkpoint\n",
      "    metric_value = metrics[metric_to_check]\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'eval_aggregate_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2467, in _inner_training_loop\n",
      "    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2918, in _maybe_log_save_evaluate\n",
      "    self._save_checkpoint(model, trial, metrics=metrics)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3024, in _save_checkpoint\n",
      "    raise KeyError(\n",
      "KeyError: \"The `metric_for_best_model` training argument is set to 'eval_aggregate_score', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_all-nli-triplet_loss', 'eval_sts-dev_pearson_cosine', 'eval_sts-dev_spearman_cosine', 'eval_sts-dev_pearson_manhattan', 'eval_sts-dev_spearman_manhattan', 'eval_sts-dev_pearson_euclidean', 'eval_sts-dev_spearman_euclidean', 'eval_sts-dev_pearson_dot', 'eval_sts-dev_spearman_dot', 'eval_sts-dev_pearson_max', 'eval_sts-dev_spearman_max', 'eval_triplet-dev_cosine_accuracy', 'eval_triplet-dev_dot_accuracy', 'eval_triplet-dev_manhattan_accuracy', 'eval_triplet-dev_euclidean_accuracy', 'eval_triplet-dev_max_accuracy', 'eval_label-accuracy-dev_pearson_cosine', 'eval_label-accuracy-dev_spearman_cosine', 'eval_label-accuracy-dev_pearson_manhattan', 'eval_label-accuracy-dev_spearman_manhattan', 'eval_label-accuracy-dev_pearson_euclidean', 'eval_label-accuracy-dev_spearman_euclidean', 'eval_label-accuracy-dev_pearson_dot', 'eval_label-accuracy-dev_spearman_dot', 'eval_label-accuracy-dev_pearson_max', 'eval_label-accuracy-dev_spearman_max', 'eval_sequential_score', 'eval_all-nli-triplet_runtime', 'eval_all-nli-triplet_samples_per_second', 'eval_all-nli-triplet_steps_per_second', 'epoch', 'aggregate_score', 'eval_stsb_loss', 'eval_stsb_runtime', 'eval_stsb_samples_per_second', 'eval_stsb_steps_per_second', 'eval_quora_loss', 'eval_quora_runtime', 'eval_quora_samples_per_second', 'eval_quora_steps_per_second', 'eval_natural-questions_loss', 'eval_natural-questions_runtime', 'eval_natural-questions_samples_per_second', 'eval_natural-questions_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 8yu15rc5 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3022, in _save_checkpoint\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     metric_value = metrics[metric_to_check]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'eval_aggregate_score'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The above exception was the direct cause of the following exception:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2467, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2918, in _maybe_log_save_evaluate\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._save_checkpoint(model, trial, metrics=metrics)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3024, in _save_checkpoint\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise KeyError(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: \"The `metric_for_best_model` training argument is set to 'eval_aggregate_score', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_all-nli-triplet_loss', 'eval_sts-dev_pearson_cosine', 'eval_sts-dev_spearman_cosine', 'eval_sts-dev_pearson_manhattan', 'eval_sts-dev_spearman_manhattan', 'eval_sts-dev_pearson_euclidean', 'eval_sts-dev_spearman_euclidean', 'eval_sts-dev_pearson_dot', 'eval_sts-dev_spearman_dot', 'eval_sts-dev_pearson_max', 'eval_sts-dev_spearman_max', 'eval_triplet-dev_cosine_accuracy', 'eval_triplet-dev_dot_accuracy', 'eval_triplet-dev_manhattan_accuracy', 'eval_triplet-dev_euclidean_accuracy', 'eval_triplet-dev_max_accuracy', 'eval_label-accuracy-dev_pearson_cosine', 'eval_label-accuracy-dev_spearman_cosine', 'eval_label-accuracy-dev_pearson_manhattan', 'eval_label-accuracy-dev_spearman_manhattan', 'eval_label-accuracy-dev_pearson_euclidean', 'eval_label-accuracy-dev_spearman_euclidean', 'eval_label-accuracy-dev_pearson_dot', 'eval_label-accuracy-dev_spearman_dot', 'eval_label-accuracy-dev_pearson_max', 'eval_label-accuracy-dev_spearman_max', 'eval_sequential_score', 'eval_all-nli-triplet_runtime', 'eval_all-nli-triplet_samples_per_second', 'eval_all-nli-triplet_steps_per_second', 'epoch', 'aggregate_score', 'eval_stsb_loss', 'eval_stsb_runtime', 'eval_stsb_samples_per_second', 'eval_stsb_steps_per_second', 'eval_quora_loss', 'eval_quora_runtime', 'eval_quora_samples_per_second', 'eval_quora_steps_per_second', 'eval_natural-questions_loss', 'eval_natural-questions_runtime', 'eval_natural-questions_samples_per_second', 'eval_natural-questions_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tqw17xxr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025375646219340177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241121_223836-tqw17xxr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/tqw17xxr' target=\"_blank\">silvery-sweep-2</a></strong> to <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/tqw17xxr' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/tqw17xxr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b52da231f149a58760a4c63ad88ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3518, in training_step\n",
      "    self.accelerator.backward(loss, **kwargs)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/accelerate/accelerator.py\", line 2246, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 290.00 MiB. GPU \n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-sweep-2</strong> at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/tqw17xxr' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/tqw17xxr</a><br/> View project at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_223836-tqw17xxr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run tqw17xxr errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3518, in training_step\n",
      "    self.accelerator.backward(loss, **kwargs)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/accelerate/accelerator.py\", line 2246, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 290.00 MiB. GPU \n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run tqw17xxr errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     tr_loss_step = self.training_step(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3518, in training_step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.accelerator.backward(loss, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/accelerate/accelerator.py\", line 2246, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss.backward(**kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.autograd.backward(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _engine_run_backward(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 290.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7245cnsz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001114676136922844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241121_224024-7245cnsz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/7245cnsz' target=\"_blank\">dark-sweep-3</a></strong> to <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/7245cnsz' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/7245cnsz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ec6ff3ba71434f89a56563ba04745b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-3</strong> at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/7245cnsz' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/7245cnsz</a><br/> View project at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_224024-7245cnsz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 7245cnsz errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7245cnsz errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     tr_loss_step = self.training_step(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = self.compute_loss(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = loss_fn(features, labels)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output.reraise()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Original Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = module(*input, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return super().forward(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     input = module(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     encoder_outputs = self.encoder(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     layer_outputs = layer_module(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_attn_outputs = self.attention(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_outputs = self.self(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: saiil1bc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00012301289826675447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241121_224040-saiil1bc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/saiil1bc' target=\"_blank\">absurd-sweep-4</a></strong> to <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/saiil1bc' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/saiil1bc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c71d385d454faa92a48431aed3d676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-sweep-4</strong> at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/saiil1bc' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/saiil1bc</a><br/> View project at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_224040-saiil1bc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run saiil1bc errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run saiil1bc errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     tr_loss_step = self.training_step(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = self.compute_loss(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = loss_fn(features, labels)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output.reraise()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Original Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = module(*input, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return super().forward(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     input = module(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     encoder_outputs = self.encoder(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     layer_outputs = layer_module(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_attn_outputs = self.attention(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_outputs = self.self(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eo60u1f0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000371834285495596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241121_224051-eo60u1f0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/eo60u1f0' target=\"_blank\">distinctive-sweep-5</a></strong> to <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/eo60u1f0' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/eo60u1f0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3693dbb0ab04cd0bfc0895375c23d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-5</strong> at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/eo60u1f0' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/eo60u1f0</a><br/> View project at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_224051-eo60u1f0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run eo60u1f0 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run eo60u1f0 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     tr_loss_step = self.training_step(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = self.compute_loss(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = loss_fn(features, labels)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output.reraise()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Original Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = module(*input, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return super().forward(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     input = module(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     encoder_outputs = self.encoder(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     layer_outputs = layer_module(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_attn_outputs = self.attention(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_outputs = self.self(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0d6ir904 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.304439853025411e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leonkrug/Documents/repos/gitlab/HSLU/AICOMP/code/notebooks/wandb/run-20241121_224101-0d6ir904</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/0d6ir904' target=\"_blank\">astral-sweep-6</a></strong> to <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/sweeps/mbg5ckdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/0d6ir904' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/0d6ir904</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5b0b625a434c99ab4fdae37f4cada2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-6</strong> at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/0d6ir904' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep/runs/0d6ir904</a><br/> View project at: <a href='https://wandb.ai/hslu_nlp/sentence-transformers-sweep' target=\"_blank\">https://wandb.ai/hslu_nlp/sentence-transformers-sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_224101-0d6ir904/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 0d6ir904 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "    trainer.train()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "    loss = loss_fn(features, labels)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "    reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "    return super().forward(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "    self_attn_outputs = self.attention(\n",
      "                        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "    self_outputs = self.self(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "    attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0d6ir904 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_8990/1301178606.py\", line 179, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2052, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 2388, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     tr_loss_step = self.training_step(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/trainer.py\", line 3485, in training_step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = self.compute_loss(model, inputs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/trainer.py\", line 344, in compute_loss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = loss_fn(features, labels)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\", line 99, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output.reraise()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/_utils.py\", line 705, in reraise\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Original Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = module(*input, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 663, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return super().forward(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     input = module(input)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 118, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1729, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     encoder_outputs = self.encoder(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1309, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     layer_outputs = layer_module(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1237, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_attn_outputs = self.attention(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1173, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self_outputs = self.self(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py\", line 635, in forward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_probs = nn.functional.dropout(attn_probs, p=self.dropout, training=self.training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/leonkrug/anaconda3/envs/aicomp/lib/python3.11/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "Detected 5 failed runs in a row at start, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 5 failed runs in a row at start, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca74e780316a44058fe08c7689f0c5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/595M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Leo1212/longformer-base-4096-sentence-transformers-best/commit/dce6d431c10e096140bece902bd3ee75d54e20a1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.losses import CoSENTLoss, MultipleNegativesRankingLoss, SoftmaxLoss\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, TripletEvaluator, LabelAccuracyEvaluator, SequentialEvaluator\n",
    "from transformers import EarlyStoppingCallback\n",
    "import wandb\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "\n",
    "# Initialize W&B project\n",
    "wandb.login(key=os.getenv('WANDB_API_TOKEN'))\n",
    "\n",
    "base_model_username = 'allenai'\n",
    "base_model_name = 'longformer-base-4096'\n",
    "\n",
    "# 1. Load a model to finetune\n",
    "model = SentenceTransformer(f\"{base_model_username}/{base_model_name}\")\n",
    "\n",
    "# 2. Load datasets for training and evaluation\n",
    "train_dataset = {\n",
    "    \"all-nli-pair\": load_dataset(\"sentence-transformers/all-nli\", \"pair\", split=\"train[:10000]\"),\n",
    "    \"all-nli-pair-class\": load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"train[:10000]\"),\n",
    "    \"all-nli-pair-score\": load_dataset(\"sentence-transformers/all-nli\", \"pair-score\", split=\"train[:10000]\"),\n",
    "    \"all-nli-triplet\": load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"train[:10000]\"),\n",
    "    \"stsb\": load_dataset(\"sentence-transformers/stsb\", split=\"train[:10000]\"),\n",
    "    \"quora\": load_dataset(\"sentence-transformers/quora-duplicates\", \"pair\", split=\"train[:10000]\"),\n",
    "    \"natural-questions\": load_dataset(\"sentence-transformers/natural-questions\", split=\"train[:10000]\"),\n",
    "}\n",
    "\n",
    "eval_dataset = {\n",
    "    \"all-nli-triplet\": load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"dev\"),\n",
    "    \"stsb\": load_dataset(\"sentence-transformers/stsb\", split=\"validation\"),\n",
    "    \"quora\": load_dataset(\"sentence-transformers/quora-duplicates\", \"pair\", split=\"train[10000:11000]\"),\n",
    "    \"natural-questions\": load_dataset(\"sentence-transformers/natural-questions\", split=\"train[10000:11000]\"),\n",
    "}\n",
    "\n",
    "# Define loss functions\n",
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "num_labels = len(set(train_dataset[\"all-nli-pair-class\"][\"label\"]))\n",
    "mnrl_loss = MultipleNegativesRankingLoss(model)\n",
    "softmax_loss = SoftmaxLoss(model, sentence_embedding_dimension=embedding_dim, num_labels=num_labels)\n",
    "cosent_loss = CoSENTLoss(model)\n",
    "\n",
    "losses = {\n",
    "    \"all-nli-pair\": mnrl_loss,\n",
    "    \"all-nli-pair-class\": softmax_loss,\n",
    "    \"all-nli-pair-score\": cosent_loss,\n",
    "    \"all-nli-triplet\": mnrl_loss,\n",
    "    \"stsb\": cosent_loss,\n",
    "    \"quora\": mnrl_loss,\n",
    "    \"natural-questions\": mnrl_loss,\n",
    "}\n",
    "\n",
    "# Define evaluators for each dataset\n",
    "stsb_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=eval_dataset[\"stsb\"][\"sentence1\"],\n",
    "    sentences2=eval_dataset[\"stsb\"][\"sentence2\"],\n",
    "    scores=eval_dataset[\"stsb\"][\"score\"],\n",
    "    name=\"sts-dev\",\n",
    ")\n",
    "\n",
    "all_nli_triplet_evaluator = TripletEvaluator(\n",
    "    anchors=eval_dataset[\"all-nli-triplet\"][\"anchor\"],\n",
    "    positives=eval_dataset[\"all-nli-triplet\"][\"positive\"],\n",
    "    negatives=eval_dataset[\"all-nli-triplet\"][\"negative\"],\n",
    "    name=\"triplet-dev\",\n",
    ")\n",
    "\n",
    "# Create EmbeddingSimilarityEvaluator for classification tasks\n",
    "label_accuracy_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=train_dataset[\"all-nli-pair-class\"][\"premise\"],  # Premises\n",
    "    sentences2=train_dataset[\"all-nli-pair-class\"][\"hypothesis\"],  # Hypotheses\n",
    "    scores=train_dataset[\"all-nli-pair-class\"][\"label\"],  # Ground-truth labels\n",
    "    name=\"label-accuracy-dev\",\n",
    ")\n",
    "\n",
    "\n",
    "# Combine evaluators into a SequentialEvaluator\n",
    "evaluator = SequentialEvaluator(\n",
    "    [stsb_evaluator, all_nli_triplet_evaluator, label_accuracy_evaluator],\n",
    "    main_score_function=lambda scores: scores[-1] if scores else 0,\n",
    ")\n",
    "\n",
    "# Define custom aggregate metric\n",
    "def compute_aggregate_metric(metrics):\n",
    "    \"\"\"\n",
    "    Combine metrics from multiple evaluators into a single score for optimization.\n",
    "    \"\"\"\n",
    "    stsb_score = metrics.get(\"eval_sts-dev_spearman_cosine\", 0)\n",
    "    triplet_score = metrics.get(\"eval_triplet-dev_mean_rank\", 0)  # Replace with actual triplet metric key\n",
    "    label_accuracy_score = metrics.get(\"eval_label-accuracy-dev_accuracy\", 0)\n",
    "\n",
    "    # Weighted average of metrics\n",
    "    aggregate_score = (\n",
    "        0.4 * stsb_score +\n",
    "        0.4 * triplet_score +\n",
    "        0.2 * label_accuracy_score\n",
    "    )\n",
    "    return aggregate_score\n",
    "\n",
    "# Define W&B sweep configuration\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"aggregate_score\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\"min\": 2e-5, \"max\": 5e-4},\n",
    "        \"warmup_steps\": {\"values\": [0.1, 0.2, 0.3]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initialize W&B sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"sentence-transformers-sweep\")\n",
    "\n",
    "# Define training function\n",
    "def train_model(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Define training arguments\n",
    "        total_steps = len(train_dataset)\n",
    "        warmup_steps = int(config.warmup_steps * total_steps)\n",
    "\n",
    "        training_args = SentenceTransformerTrainingArguments(\n",
    "            output_dir=f\"./{base_model_name}-fine-tuned\",\n",
    "            overwrite_output_dir=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=500,\n",
    "            save_total_limit=3,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"aggregate_score\",  # Use custom metric here\n",
    "            greater_is_better=True,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=10,\n",
    "            warmup_steps=warmup_steps,\n",
    "            learning_rate=config.learning_rate,\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=200,\n",
    "            save_steps=500,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)\n",
    "\n",
    "        # Define SequentialEvaluator\n",
    "        evaluator = SequentialEvaluator(\n",
    "            [stsb_evaluator, all_nli_triplet_evaluator, label_accuracy_evaluator],\n",
    "            main_score_function=lambda scores: scores[-1] if scores else 0,\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        trainer = SentenceTransformerTrainer(\n",
    "            model=model,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            loss=losses,\n",
    "            args=training_args,\n",
    "            evaluator=evaluator,\n",
    "            callbacks=[early_stopping],\n",
    "        )\n",
    "\n",
    "        # Save a reference to the original evaluate method\n",
    "        original_evaluate = trainer.evaluate\n",
    "\n",
    "        # Wrap evaluation to include custom aggregate metric\n",
    "        def custom_evaluate(*args, **kwargs):\n",
    "            metrics = original_evaluate(*args, **kwargs)  # Call the original evaluate method\n",
    "            # Calculate the aggregate score\n",
    "            aggregate_score = compute_aggregate_metric(metrics)\n",
    "            metrics[\"aggregate_score\"] = aggregate_score\n",
    "            wandb.log({\"aggregate_score\": aggregate_score})\n",
    "            return metrics\n",
    "\n",
    "        # Override the trainer's evaluate function\n",
    "        trainer.evaluate = custom_evaluate\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # Save the model\n",
    "        model.save_pretrained(f\"{base_model_name}-best-model\")\n",
    "        wandb.save(f\"{base_model_name}-best-model/*\")\n",
    "\n",
    "\n",
    "\n",
    "# Start W&B agent for the sweep\n",
    "wandb.agent(sweep_id, function=train_model)\n",
    "\n",
    "# Push the best model to the Hugging Face Hub with W&B config\n",
    "model.push_to_hub(\n",
    "    f\"{base_model_name}-sentence-transformers-best\",\n",
    "    exist_ok=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
